{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4577a5d4",
   "metadata": {},
   "source": [
    "# Project 2 - Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c48d26f",
   "metadata": {},
   "source": [
    "In this project, you will work with a ships in satellite imagery dataset. You will implement dimensionality reduction and manifold learning techniques for visualization and subsequent classification tasks to report on a set of questions.\n",
    "\n",
    "The goal of this project includes:\n",
    "\n",
    "1. Dataset visualization and interpretability via dimensionality reduction\n",
    "2. Implement dimensionality reduction techniques with ```scikit-learn```\n",
    "3. Carry out experiments to select best subspace projections\n",
    "4. Design pipelines for hyperparameter tuning and model selection\n",
    "5. Implement performance evaluation metrics and evaluate results\n",
    "6. Report observations, propose business-centric solutions and propose mitigating strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b18caaa-bd91-4fa1-bd81-dda84f4ae140",
   "metadata": {},
   "source": [
    "## Deliverables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb484cc",
   "metadata": {},
   "source": [
    "As part of this project, you should deliver the following materials:\n",
    "\n",
    "1. [**4-page IEEE-format paper**](https://www.ieee.org/conferences/publishing/templates.html). Write a paper with no more than 4 pages addressing the questions posed below. When writing this report, consider a business-oriented person as your reader (e.g. your PhD advisor, your internship manager, etc.). Tell *the story* for each datasets' goal and propose solutions by addressing (at least) the questions posed below.\n",
    "\n",
    "2. **Python Code**. Create two separate Notebooks: (1) \"training.ipynb\" used for training and hyperparameter tuning, (2) \"test.ipynb\" for evaluating the final trained model in the test set. The \"test.ipynb\" should load all trained objects and simply evaluate the performance. So don't forget to **push the trained models** to your repository to allow us to run it.\n",
    "\n",
    "All of your code should run without any errors and be well-documented. \n",
    "\n",
    "3. **README.md file**. Edit the readme.md file in your repository and how to use your code. If there are user-defined parameters, your readme.md file must clearly indicate so and demonstrate how to use your code. **Consider the case where the user wants to utilize your code to run on a different test set. Indicate in your readme.md file how this can be achieved.**\n",
    "\n",
    "This is an **individual assignment**. \n",
    "\n",
    "Late submissions will not be accepted, so please plan accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04efb838",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af17a9",
   "metadata": {},
   "source": [
    "# About the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dc2f64",
   "metadata": {},
   "source": [
    "Satellite imagery provides unique insights into various markets, including agriculture, defense and intelligence, energy, and finance. New commercial imagery providers, such as [Planet](https://www.planet.com/), are using constellations of small satellites to capture images of the entire Earth every day.\n",
    "\n",
    "This flood of new imagery is outgrowing the ability for organizations to manually look at each image that gets captured, and there is a need for machine learning and computer vision algorithms to help automate the analysis process.\n",
    "\n",
    "The aim of this dataset is to help address the difficult task of detecting the location of large ships in satellite images. Automating this process can be applied to many issues including monitoring port activity levels and supply chain analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb22fe27-f818-4118-9e49-0f0e4805ee88",
   "metadata": {},
   "source": [
    "### Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebc4da1-82f8-4042-86aa-20b9f6683825",
   "metadata": {},
   "source": [
    "The dataset consists of images extracted from Planet satellite imagery collected over the San Francisco Bay and San Pedro Bay areas of California. It includes 4000 $80\\times 80$ RGB images labeled with either a \"ship\" or \"no-ship\" classification. Images were derived from PlanetScope full-frame visual scene products, which are orthorectified to a 3-meter pixel size.\n",
    "\n",
    "* ```ship_data.npy```: contains all 4000 $80\\times 80$ RGB images.\n",
    "* ```ship_labels.npy```: valued 1 or 0, representing the \"ship\" class and \"no-ship\" class, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9140fb4b-e330-4d91-83ee-d186cce6e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "from pylab import rcParams\n",
    "\n",
    "# Awesome plots\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\", {'axes.grid': True,\n",
    "                            'axes.edgecolor': 'black'\n",
    "                            })\n",
    "\n",
    "# Load the dataset\n",
    "X = np.load('ships_dataset/ship_data.npy')\n",
    "t = np.load('ships_dataset/ship_labels.npy')\n",
    "\n",
    "label_names = ['no_ship', 'ship']\n",
    "\n",
    "X.shape, t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ba7ff6-8b36-404f-9cdb-e794a62d7040",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bc7f08-2aa4-459d-9bf7-7eb352b3f61b",
   "metadata": {},
   "source": [
    "The \"ship\" class includes 1000 images. Images in this class are centered on the body of a single ship. Ships of different sizes, orientations, and atmospheric collection conditions are included. Example images from this class are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8a27a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ship images\n",
    "\n",
    "rnd_sample = npr.permutation(np.where(t==1)[0])\n",
    "fig=plt.figure(figsize=(15,5))\n",
    "for j in range(18):\n",
    "    fig.add_subplot(3,6,j+1)\n",
    "    plt.imshow(X[rnd_sample[j]])\n",
    "    plt.axis('off');plt.title(label_names[t[rnd_sample[j]]],size=15)\n",
    "plt.show()\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093ee643-b51a-4f24-8ad7-ed00292f6d36",
   "metadata": {},
   "source": [
    "The \"no-ship\" class includes 3000 images. A third of these are a random sampling of different land cover features - water, vegetation, bare earth, buildings, etc. - that do not include any portion of a ship. The next third are \"partial ships\" that contain only a portion of a ship, but not enough to meet the full definition of the \"ship\" class. The last third are images that have previously been mislabeled by machine learning models, typically caused by bright pixels or strong linear features. Example images from this class are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8d0075-9a2f-4d9d-ab14-a90f75c4fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_ship images\n",
    "\n",
    "rnd_sample = npr.permutation(np.where(t==0)[0])\n",
    "fig=plt.figure(figsize=(15,5))\n",
    "for j in range(18):\n",
    "    fig.add_subplot(3,6,j+1)\n",
    "    plt.imshow(X[rnd_sample[j]])\n",
    "    plt.axis('off');plt.title(label_names[t[rnd_sample[j]]],size=15)\n",
    "plt.show()\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f0b374-8424-42e2-9259-8e7deb32ff62",
   "metadata": {},
   "source": [
    "### Scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07780af3-f19f-47cd-b674-3abdfcc68f80",
   "metadata": {},
   "source": [
    "Eight full-scene images are included in the \"**scenes**\" directory. Scenes can be used to visualize the performance of classification models trained on the dataset. Verify a model's accuracy by applying it across a scene and viewing where 'ship' classifications occur - the context provided by the scene helps determine positive hits from false alarms. An example scene is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f20a8e-cc5d-4ef8-bc1b-034c4e6df735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "bay_name = ['San Pedro Bay']*4 + ['San Francisco Bay']*4\n",
    "\n",
    "directory = 'ships_dataset/scenes/'\n",
    "plt.figure(figsize=(15,5))\n",
    "j=1\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith('.png'):\n",
    "        filename = directory+'/'+file\n",
    "        # Loads image\n",
    "        image = np.array(Image.open(filename).convert('RGB'))\n",
    "        plt.subplot(2,4,j); plt.imshow(image); plt.axis('off');plt.title(bay_name[j-1])\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3144a60f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bf5178",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896a778e-81a7-48d1-8323-71f2287812d5",
   "metadata": {},
   "source": [
    "1. Train at least two classifiers without dimensionality reduction on this dataset.\n",
    "    * Carry the standard hyperparameter tuning.\n",
    "    * Report performance measures (accuracy score and f1-score), and training time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8595149b-fd87-48bd-a4a4-3fceb27bdbfa",
   "metadata": {},
   "source": [
    "2. Train a ```pipeline``` to perform dimensionality reduction with Principal Component Analysis (PCA). Answer the following questions:\n",
    "    * How many components are needed to explain 90% of the variance?\n",
    "    * Visualize examples of \"ship\" and \"no_ship\" image reconstructions. What is the average RMSE of the reconstruction as a function of number of components preserved?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f801f3bc-8d87-45c5-ae6e-94bb3bd78008",
   "metadata": {},
   "source": [
    "3. Train a ```pipeline``` for the same classifiers in part (1) with dimensionality reduction via PCA.\n",
    "    * Carry the standard hyperparameter tuning (including ```n_components```).\n",
    "    * Compare performance measures and training time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed14a3e-c4e9-4eb2-a813-5e6277893bcf",
   "metadata": {},
   "source": [
    "4. Repeat question (3) for using manifold learning algorithms. Utilize the new lower-dimensional feature space to build a classifier.\n",
    "    * Use the same classifiers.\n",
    "    * Compare performance metrics and training/inference time with those for question (3) and (1).\n",
    "    * Visualize and interpret what the first 2 dimensions in the manifold learning algorithms you train. Use the ```plot_components``` function presented in lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b6f8d6-ab3f-4689-af1d-cf63d01d1b2a",
   "metadata": {},
   "source": [
    "5. What is the overall best ```pipeline```?\n",
    "    * Report the confusion matrices.\n",
    "    * Visualize misclassified samples. Do you see a pattern? Provide a discussion on how you would move forward to address the misclassifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c067002",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21b9936",
   "metadata": {},
   "source": [
    "### Test Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6f86f3-fe4a-4aa4-b462-497f1a485560",
   "metadata": {},
   "source": [
    "6. Report performance and inference time on your test set for questions 1, 3 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13d3024-ee4e-41cd-aa87-5570d4ee5963",
   "metadata": {},
   "source": [
    "7. Create a function that loads one satellite image (examples inside the ```scene``` folder), runs your best model across a scene and displays where a \"ship\" classification occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24bc40d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66027c2c",
   "metadata": {},
   "source": [
    "# Submit Your Solution\n",
    "\n",
    "Confirm that you've successfully completed the assignment.\n",
    "\n",
    "Along with the Notebook, include a PDF of the notebook with your solutions.\n",
    "\n",
    "```add``` and ```commit``` the final version of your work, and ```push``` your code to your GitHub repository.\n",
    "\n",
    "Submit the URL of your GitHub Repository as your assignment submission on Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa2d31e",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
